{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyteomics.mzml\n",
    "import pandas as pd\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects import pandas2ri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to generate correlations between:\n",
    "\n",
    "    2ngQ VS 2ngQ\n",
    "    0.2ngQ VS 0.2ngQ\n",
    "    scQ vs scQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_precursor_peak(df):\n",
    "    #if there is a peak that is 10X more intense than everything else, get rid of it (it's a precursor that hasn't been fragmented)\n",
    "    maxpeak = df['intensity'].max()\n",
    "    \n",
    "    #if it's ten times more intesne that all the other peaks get rid of it. \n",
    "    rm_max_peak = df[df['intensity']!=maxpeak]\n",
    "    mean_intensity = rm_max_peak['intensity'].nlargest(10).mean()\n",
    "    \n",
    "    if maxpeak >= 5*mean_intensity:\n",
    "        \n",
    "        #also remove the plusone isotope\n",
    "        maxmz = df[df['intensity'] == maxpeak]['mz'].values[0]\n",
    "        plusone = maxmz + 1.0034\n",
    "        plusone_tol_max = plusone+.01\n",
    "        plusone_tol_min = plusone-.01\n",
    "        \n",
    "        plusonemz_array = rm_max_peak[(rm_max_peak['mz'] <= plusone_tol_max) & (rm_max_peak['mz'] >= plusone_tol_min)]['mz'].values\n",
    "        if len(plusonemz_array > 0 ): #if there is a plus1 isotope\n",
    "            plusonemz = plusonemz_array[0]\n",
    "            rm_max_peak = rm_max_peak[rm_max_peak['mz']!=plusonemz]\n",
    "        \n",
    "        return rm_max_peak\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_dfs(scan1, scan2, mzml1, mzml2):\n",
    "    spectrum_dict1 = mzml1.get_by_id(\"controllerType=0 controllerNumber=1 scan=\"+scan1)\n",
    "    spectrum_id1 = spectrum_dict1['id']\n",
    "    mz_array1 = spectrum_dict1['m/z array']\n",
    "    intensity_array1 = spectrum_dict1['intensity array']\n",
    "    \n",
    "    spectrum_dict2 = mzml2.get_by_id(\"controllerType=0 controllerNumber=1 scan=\"+scan2)\n",
    "    spectrum_id2 = spectrum_dict2['id']\n",
    "    mz_array2 = spectrum_dict2['m/z array']\n",
    "    intensity_array2 = spectrum_dict2['intensity array']\n",
    "    \n",
    "    \n",
    "    df1 = pd.DataFrame({'mz':mz_array1, 'intensity':intensity_array1 })\n",
    "    df2 = pd.DataFrame({'mz':mz_array2, 'intensity':intensity_array2 })\n",
    "\n",
    "    df1 = remove_precursor_peak(df1)\n",
    "    df2 = remove_precursor_peak(df2)\n",
    "    \n",
    "    return df1, df2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get comparisons\n",
    "all_combos = pd.read_csv('data/list_of_spectra_to_compare/all_combos.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the R script and loading the instance in Python\n",
    "r = robjects.r\n",
    "r['source']('calc_cosine_score.R')\n",
    "SpectrumSimilarity = robjects.globalenv['SpectrumSimilarity']  # Loading the function we have defined in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_list = ['Ex_Auto_J3_30umTB_2ngQC_60m_1', 'Ex_Auto_J3_30umTB_2ngQC_60m_2',\n",
    "             'Ex_Auto_K13_30umTA_2ngQC_60m_1', 'Ex_Auto_K13_30umTA_2ngQC_60m_2',\n",
    "             'Ex_Auto_W17_30umTB_2ngQC_60m_1', 'Ex_Auto_W17_30umTB_2ngQC_60m_2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 07:34:58\n",
      "File1: Ex_Auto_J3_30umTB_2ngQC_60m_1\n",
      "File2: Ex_Auto_J3_30umTB_2ngQC_60m_1\n",
      "File2: Ex_Auto_J3_30umTB_2ngQC_60m_2\n",
      "File2: Ex_Auto_W17_30umTB_2ngQC_60m_1\n",
      "File2: Ex_Auto_W17_30umTB_2ngQC_60m_2\n",
      "File2: Ex_Auto_K13_30umTA_2ngQC_60m_1\n",
      "File2: Ex_Auto_K13_30umTA_2ngQC_60m_2\n",
      "File2: OR11_20160122_PG_HeLa_CVB3_CT_A\n",
      "File2: OR11_20160122_PG_HeLa_CVB3_CT_B\n",
      "File2: OR11_20160122_PG_HeLa_CVB3_CT_C\n",
      "File1: Ex_Auto_J3_30umTB_2ngQC_60m_2\n",
      "File2: Ex_Auto_J3_30umTB_2ngQC_60m_2\n",
      "File2: Ex_Auto_W17_30umTB_2ngQC_60m_1\n",
      "File2: Ex_Auto_W17_30umTB_2ngQC_60m_2\n",
      "File2: Ex_Auto_K13_30umTA_2ngQC_60m_1\n",
      "File2: Ex_Auto_K13_30umTA_2ngQC_60m_2\n",
      "File2: OR11_20160122_PG_HeLa_CVB3_CT_A\n",
      "File2: OR11_20160122_PG_HeLa_CVB3_CT_B\n",
      "File2: OR11_20160122_PG_HeLa_CVB3_CT_C\n",
      "File1: Ex_Auto_K13_30umTA_2ngQC_60m_1\n",
      "File2: Ex_Auto_W17_30umTB_2ngQC_60m_1\n",
      "File2: Ex_Auto_W17_30umTB_2ngQC_60m_2\n",
      "File2: Ex_Auto_K13_30umTA_2ngQC_60m_1\n",
      "File2: Ex_Auto_K13_30umTA_2ngQC_60m_2\n",
      "File2: OR11_20160122_PG_HeLa_CVB3_CT_A\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)  \n",
    "\n",
    "counter_for_list_removal = 0\n",
    "sc2ngQ_v_sc2ngQ = []\n",
    "sc2ngQ_v_bulk = []\n",
    "for file1_name in file1_list:\n",
    "    print(\"File1: \"+file1_name)\n",
    "    #devide up based on file \n",
    "    \n",
    "    rep1_rep1 = all_combos[(all_combos['File1']==file1_name)&\n",
    "                                     (all_combos['File2']=='Ex_Auto_J3_30umTB_2ngQC_60m_1')]\n",
    "    rep1_rep2 = all_combos[(all_combos['File1']==file1_name)&\n",
    "                                     (all_combos['File2']=='Ex_Auto_J3_30umTB_2ngQC_60m_2')]\n",
    "    rep1_rep3 = all_combos[(all_combos['File1']==file1_name)&\n",
    "                                     (all_combos['File2']=='Ex_Auto_W17_30umTB_2ngQC_60m_1')]\n",
    "    rep1_rep4 = all_combos[(all_combos['File1']==file1_name)&\n",
    "                                     (all_combos['File2']=='Ex_Auto_W17_30umTB_2ngQC_60m_2')]\n",
    "    rep1_rep5 = all_combos[(all_combos['File1']==file1_name)&\n",
    "                                     (all_combos['File2']=='Ex_Auto_K13_30umTA_2ngQC_60m_1')]\n",
    "    rep1_rep6 = all_combos[(all_combos['File1']==file1_name)&\n",
    "                                     (all_combos['File2']=='Ex_Auto_K13_30umTA_2ngQC_60m_2')]\n",
    "\n",
    "    \n",
    "    rep1_bulkrep1 = all_combos[(all_combos['File1']==file1_name)&\n",
    "                                     (all_combos['File2']=='OR11_20160122_PG_HeLa_CVB3_CT_A')]\n",
    "    rep1_bulkrep2 = all_combos[(all_combos['File1']==file1_name)&\n",
    "                                     (all_combos['File2']=='OR11_20160122_PG_HeLa_CVB3_CT_B')]\n",
    "    rep1_bulkrep3 = all_combos[(all_combos['File1']==file1_name)&\n",
    "                                     (all_combos['File2']=='OR11_20160122_PG_HeLa_CVB3_CT_C')]\n",
    "\n",
    "\n",
    "\n",
    "    rep1_rep1 = rep1_rep1[['Scan1','Scan2', 'type']].to_numpy()\n",
    "    rep1_rep2 = rep1_rep2[['Scan1','Scan2', 'type']].to_numpy()\n",
    "    rep1_rep3 = rep1_rep3[['Scan1','Scan2', 'type']].to_numpy()\n",
    "    rep1_rep4 = rep1_rep4[['Scan1','Scan2', 'type']].to_numpy()\n",
    "    rep1_rep5 = rep1_rep5[['Scan1','Scan2', 'type']].to_numpy()\n",
    "    rep1_rep6 = rep1_rep6[['Scan1','Scan2', 'type']].to_numpy()\n",
    "\n",
    "    rep1_bulkrep1 = rep1_bulkrep1[['Scan1','Scan2', 'type']].to_numpy()\n",
    "    rep1_bulkrep2 = rep1_bulkrep2[['Scan1','Scan2', 'type']].to_numpy()\n",
    "    rep1_bulkrep3 = rep1_bulkrep3[['Scan1','Scan2', 'type']].to_numpy()\n",
    "    \n",
    "    file1_path = 'data/mzMLs/'\n",
    "    file1_path = file1_path+file1_name+\".mzML\"\n",
    "    file1 = pyteomics.mzml.MzML(file1_path)\n",
    "    \n",
    "    \n",
    "    list_of_scans = [rep1_rep1,rep1_rep2,rep1_rep3,rep1_rep4,rep1_rep5,rep1_rep6,\n",
    "                        rep1_bulkrep1,rep1_bulkrep2,rep1_bulkrep3]\n",
    "    \n",
    "    file2_list = ['Ex_Auto_J3_30umTB_2ngQC_60m_1','Ex_Auto_J3_30umTB_2ngQC_60m_2',\n",
    "              'Ex_Auto_W17_30umTB_2ngQC_60m_1','Ex_Auto_W17_30umTB_2ngQC_60m_2',\n",
    "             'Ex_Auto_K13_30umTA_2ngQC_60m_1','Ex_Auto_K13_30umTA_2ngQC_60m_2',\n",
    "\n",
    "             'OR11_20160122_PG_HeLa_CVB3_CT_A',\n",
    "             'OR11_20160122_PG_HeLa_CVB3_CT_B',\n",
    "             'OR11_20160122_PG_HeLa_CVB3_CT_C']\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #remove items from list1 so that we don't make duplicate comparisons\n",
    "    list_of_scans = list_of_scans[counter_for_list_removal: len(list_of_scans)]\n",
    "    file2_list = file2_list[counter_for_list_removal: len(file2_list)]\n",
    "    \n",
    "    for i in range(0, len(file2_list)):\n",
    "        file2_name = file2_list[i]\n",
    "        file2_path = 'data/mzMLs/'\n",
    "        file2_path = file2_path+file2_name+\".mzML\"\n",
    "        file2 = pyteomics.mzml.MzML(file2_path)\n",
    "\n",
    "        scans_to_compare = list_of_scans[i]\n",
    "\n",
    "        print(\"File2: \"+file2_name)\n",
    "        for scan_pair in scans_to_compare:\n",
    "            scan1 = scan_pair[0]\n",
    "            scan2 = scan_pair[1]\n",
    "            comp_typo = scan_pair[2]\n",
    "\n",
    "            df1, df2 = get_dfs(str(scan1), str(scan2), file1, file2)\n",
    "\n",
    "            pandas2ri.activate()\n",
    "            mins = [df1['mz'].min(), df2['mz'].min()]\n",
    "            maxs = [df1['mz'].max(), df2['mz'].max()]\n",
    "            sim_score = SpectrumSimilarity(df1, df2, xlim = [min(mins), max(maxs)])\n",
    "            sim_score = sim_score[0]\n",
    "            \n",
    "            if comp_typo == '2ng good vs 2ng good':\n",
    "                sc2ngQ_v_sc2ngQ.append(sim_score)\n",
    "            if comp_typo == '2ng good vs bulk good':\n",
    "                sc2ngQ_v_bulk.append(sim_score)\n",
    "    \n",
    "    \n",
    "    counter_for_list_removal += 1\n",
    "                \n",
    "                \n",
    "                \n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path('data/scores_for_figure4/').mkdir(parents=True, exist_ok=True)#make the folder that we'll store all parsed psms in\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/scores_for_figure4/sc2ngQ_v_sc2ngQ_charged.txt', 'w') as f1:\n",
    "    for item in sc2ngQ_v_sc2ngQ:\n",
    "        f1.write(\"%s\\n\" % item)\n",
    "\n",
    "        \n",
    "with open('data/scores_for_figure4/sc2ngQ_v_Bulk_charged.txt', 'w') as f4:\n",
    "    for item in sc2ngQ_v_bulk:\n",
    "        f4.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
